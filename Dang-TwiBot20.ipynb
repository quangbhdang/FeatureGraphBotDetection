{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593f174c-f5ba-4fc0-904b-357c3c4aaa79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:36:49.893145Z",
     "iopub.status.busy": "2025-05-22T03:36:49.892988Z",
     "iopub.status.idle": "2025-05-22T03:36:52.391686Z",
     "shell.execute_reply": "2025-05-22T03:36:52.391142Z",
     "shell.execute_reply.started": "2025-05-22T03:36:49.893134Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f981cf30-67ef-41a3-bf4f-32128c39f8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:36:52.392426Z",
     "iopub.status.busy": "2025-05-22T03:36:52.392144Z",
     "iopub.status.idle": "2025-05-22T03:36:54.187311Z",
     "shell.execute_reply": "2025-05-22T03:36:54.186844Z",
     "shell.execute_reply.started": "2025-05-22T03:36:52.392416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as quangbhdang\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as quangbhdang\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"quangbhdang/COSC2984-SMNA-Assignment\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"quangbhdang/COSC2984-SMNA-Assignment\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository quangbhdang/COSC2984-SMNA-Assignment initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository quangbhdang/COSC2984-SMNA-Assignment initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='quangbhdang', repo_name='COSC2984-SMNA-Assignment', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877500ca-e7a2-40b5-9957-f581edf00e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T15:15:29.863620Z",
     "iopub.status.busy": "2025-05-21T15:15:29.863451Z",
     "iopub.status.idle": "2025-05-21T15:15:36.488522Z",
     "shell.execute_reply": "2025-05-21T15:15:36.487635Z",
     "shell.execute_reply.started": "2025-05-21T15:15:29.863604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9349ca124ea249a591fbb506b1841161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UpdateNotAllowedError",
     "evalue": "Cannot update existing 'Dataset/So-Spam/relation.csv.gz' file without specifying last_commit",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUpdateNotAllowedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Upload using the DagsHub client, to a DVC tracked folder also called \"data\".\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Follow the instructions that appear to authorize the request.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdagshub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m upload_files\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdagshub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquangbhdang/COSC2984-SMNA-Assignment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDataset/So-Spam/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:210\u001b[39m, in \u001b[36mupload_files\u001b[39m\u001b[34m(repo, local_path, commit_message, remote_path, bucket, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m owner, repo = validate_owner_repo(repo)\n\u001b[32m    209\u001b[39m repo_obj = Repo(owner, repo)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[43mrepo_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:330\u001b[39m, in \u001b[36mRepo.upload\u001b[39m\u001b[34m(self, local_path, commit_message, remote_path, bucket, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_path.is_dir():\n\u001b[32m    329\u001b[39m     dir_to_upload = \u001b[38;5;28mself\u001b[39m.directory(remote_path)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     \u001b[43mdir_to_upload\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    332\u001b[39m     file_to_upload = DataSet.get_file(\u001b[38;5;28mstr\u001b[39m(local_path), PurePosixPath(remote_path))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:754\u001b[39m, in \u001b[36mDataSet.add_dir\u001b[39m\u001b[34m(self, local_path, glob_exclude, commit_message, **upload_kwargs)\u001b[39m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28mself\u001b[39m.add(file=\u001b[38;5;28mstr\u001b[39m(filepath), path=path_in_remote)\n\u001b[32m    753\u001b[39m file_counter += \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.files)\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mupload_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    755\u001b[39m progress.update(folder_task, advance=\u001b[38;5;28mlen\u001b[39m(batch), refresh=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    756\u001b[39m progress.update(total_task, completed=file_counter, refresh=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:850\u001b[39m, in \u001b[36mDataSet.commit\u001b[39m\u001b[34m(self, commit_message, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    840\u001b[39m \u001b[33;03mCommit files added with :func:`add` to the repo\u001b[39;00m\n\u001b[32m    841\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    846\u001b[39m \u001b[33;03m:func:`Repo.upload_files() <dagshub.upload.Repo.upload_files>`\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    849\u001b[39m file_list = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.files.values())\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[38;5;28mself\u001b[39m._reset_dataset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:427\u001b[39m, in \u001b[36mRepo.upload_files\u001b[39m\u001b[34m(self, files, directory_path, commit_message, versioning, new_branch, last_commit, force, quiet)\u001b[39m\n\u001b[32m    419\u001b[39m     log_message(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUploading files (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) to \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._api.full_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m, logger)\n\u001b[32m    420\u001b[39m res = s.put(\n\u001b[32m    421\u001b[39m     upload_url,\n\u001b[32m    422\u001b[39m     data=data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     timeout=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    426\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_upload_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# The ETag header contains the hash of the uploaded commit,\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# check against the one we have to determine if anything changed\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mETag\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res.headers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/graph_sm/lib/python3.12/site-packages/dagshub/upload/wrapper.py:467\u001b[39m, in \u001b[36mRepo._log_upload_details\u001b[39m\u001b[34m(self, data, res, files, quiet)\u001b[39m\n\u001b[32m    465\u001b[39m     log_message(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unknown successful status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m determine_upload_api_error(res)\n",
      "\u001b[31mUpdateNotAllowedError\u001b[39m: Cannot update existing 'Dataset/So-Spam/relation.csv.gz' file without specifying last_commit"
     ]
    }
   ],
   "source": [
    "# # Upload using the DagsHub client, to a DVC tracked folder also called \"data\".\n",
    "# # Follow the instructions that appear to authorize the request.\n",
    "# from dagshub import upload_files\n",
    "\n",
    "# dagshub.upload_files('quangbhdang/COSC2984-SMNA-Assignment', 'Dataset/So-Spam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f33b424-2768-4597-9fbb-7b5ae38f42f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:36:55.149623Z",
     "iopub.status.busy": "2025-05-22T03:36:55.149308Z",
     "iopub.status.idle": "2025-05-22T03:36:55.155325Z",
     "shell.execute_reply": "2025-05-22T03:36:55.154772Z",
     "shell.execute_reply.started": "2025-05-22T03:36:55.149611Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    output = model(des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type)\n",
    "    loss_train = loss(output[train_idx], labels[train_idx])\n",
    "    acc_train = accuracy(output[train_idx], labels[train_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "        'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "        'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "        'acc_val: {:.4f}'.format(acc_val.item()),)\n",
    "    return acc_train,loss_train\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    output = model(des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type)\n",
    "    loss_test = loss(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    output=output.max(1)[1].to('cpu').detach().numpy()\n",
    "    label=labels.to('cpu').detach().numpy()\n",
    "    f1=f1_score(label[test_idx],output[test_idx])\n",
    "    mcc=matthews_corrcoef(label[test_idx], output[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "            \"test_loss= {:.4f}\".format(loss_test.item()),\n",
    "            \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
    "            \"f1_score= {:.4f}\".format(f1),\n",
    "            \"mcc= {:.4f}\".format(mcc),\n",
    "            )\n",
    "    return acc_test,loss_test,f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb27d90-aec3-46ab-92f2-8d3f63061085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:37:05.030315Z",
     "iopub.status.busy": "2025-05-22T03:37:05.029741Z",
     "iopub.status.idle": "2025-05-22T03:37:13.298852Z",
     "shell.execute_reply": "2025-05-22T03:37:13.298273Z",
     "shell.execute_reply.started": "2025-05-22T03:37:05.030304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...   Finished\n",
      "Running feature1 embedding\n",
      "Finished\n",
      "Running feature2 embedding\n",
      "Finished\n",
      "Processing feature3...   Finished\n",
      "Processing feature4...   Finished\n",
      "Building graph   Finished\n",
      "Epoch: 0001 loss_train: 1.4881 acc_train: 0.4912 acc_val: 0.4841\n",
      "Epoch: 0002 loss_train: 1.0526 acc_train: 0.5690 acc_val: 0.5810\n",
      "Epoch: 0003 loss_train: 0.9683 acc_train: 0.6183 acc_val: 0.6334\n",
      "Epoch: 0004 loss_train: 0.8082 acc_train: 0.6505 acc_val: 0.6609\n",
      "Epoch: 0005 loss_train: 0.7274 acc_train: 0.6951 acc_val: 0.6994\n",
      "Epoch: 0006 loss_train: 0.6946 acc_train: 0.7060 acc_val: 0.7082\n",
      "Epoch: 0007 loss_train: 0.6533 acc_train: 0.7069 acc_val: 0.6964\n",
      "Epoch: 0008 loss_train: 0.6515 acc_train: 0.6982 acc_val: 0.6947\n",
      "Epoch: 0009 loss_train: 0.6026 acc_train: 0.7072 acc_val: 0.6964\n",
      "Epoch: 0010 loss_train: 0.5963 acc_train: 0.7173 acc_val: 0.7070\n",
      "Epoch: 0011 loss_train: 0.5613 acc_train: 0.7311 acc_val: 0.7268\n",
      "Epoch: 0012 loss_train: 0.5503 acc_train: 0.7589 acc_val: 0.7400\n",
      "Epoch: 0013 loss_train: 0.5180 acc_train: 0.7771 acc_val: 0.7729\n",
      "Epoch: 0014 loss_train: 0.5342 acc_train: 0.7812 acc_val: 0.7746\n",
      "Epoch: 0015 loss_train: 0.5290 acc_train: 0.7878 acc_val: 0.7772\n",
      "Epoch: 0016 loss_train: 0.5131 acc_train: 0.7861 acc_val: 0.7844\n",
      "Epoch: 0017 loss_train: 0.4936 acc_train: 0.7838 acc_val: 0.7729\n",
      "Epoch: 0018 loss_train: 0.4829 acc_train: 0.7834 acc_val: 0.7658\n",
      "Epoch: 0019 loss_train: 0.4781 acc_train: 0.7879 acc_val: 0.7767\n",
      "Epoch: 0020 loss_train: 0.4755 acc_train: 0.7873 acc_val: 0.7814\n",
      "Epoch: 0021 loss_train: 0.4754 acc_train: 0.7919 acc_val: 0.7797\n",
      "Epoch: 0022 loss_train: 0.4695 acc_train: 0.7987 acc_val: 0.7865\n",
      "Epoch: 0023 loss_train: 0.4526 acc_train: 0.8038 acc_val: 0.7937\n",
      "Epoch: 0024 loss_train: 0.4548 acc_train: 0.8048 acc_val: 0.7932\n",
      "Epoch: 0025 loss_train: 0.4336 acc_train: 0.8124 acc_val: 0.7983\n",
      "Epoch: 0026 loss_train: 0.4388 acc_train: 0.8108 acc_val: 0.7987\n",
      "Epoch: 0027 loss_train: 0.4302 acc_train: 0.8128 acc_val: 0.8047\n",
      "Epoch: 0028 loss_train: 0.4227 acc_train: 0.8157 acc_val: 0.8076\n",
      "Epoch: 0029 loss_train: 0.4175 acc_train: 0.8117 acc_val: 0.8021\n",
      "Epoch: 0030 loss_train: 0.4218 acc_train: 0.8187 acc_val: 0.7962\n",
      "Epoch: 0031 loss_train: 0.4119 acc_train: 0.8199 acc_val: 0.8114\n",
      "Epoch: 0032 loss_train: 0.4024 acc_train: 0.8253 acc_val: 0.8038\n",
      "Epoch: 0033 loss_train: 0.3977 acc_train: 0.8256 acc_val: 0.8161\n",
      "Epoch: 0034 loss_train: 0.3963 acc_train: 0.8282 acc_val: 0.8080\n",
      "Epoch: 0035 loss_train: 0.3960 acc_train: 0.8294 acc_val: 0.8199\n",
      "Epoch: 0036 loss_train: 0.3858 acc_train: 0.8328 acc_val: 0.8152\n",
      "Epoch: 0037 loss_train: 0.3812 acc_train: 0.8393 acc_val: 0.8203\n",
      "Epoch: 0038 loss_train: 0.3813 acc_train: 0.8352 acc_val: 0.8156\n",
      "Epoch: 0039 loss_train: 0.3773 acc_train: 0.8375 acc_val: 0.8233\n",
      "Epoch: 0040 loss_train: 0.3765 acc_train: 0.8374 acc_val: 0.8279\n",
      "Epoch: 0041 loss_train: 0.3699 acc_train: 0.8422 acc_val: 0.8258\n",
      "Epoch: 0042 loss_train: 0.3685 acc_train: 0.8454 acc_val: 0.8271\n",
      "Epoch: 0043 loss_train: 0.3641 acc_train: 0.8439 acc_val: 0.8326\n",
      "Epoch: 0044 loss_train: 0.3721 acc_train: 0.8428 acc_val: 0.8338\n",
      "Epoch: 0045 loss_train: 0.3600 acc_train: 0.8466 acc_val: 0.8406\n",
      "Epoch: 0046 loss_train: 0.3544 acc_train: 0.8461 acc_val: 0.8364\n",
      "Epoch: 0047 loss_train: 0.3548 acc_train: 0.8485 acc_val: 0.8414\n",
      "Epoch: 0048 loss_train: 0.3544 acc_train: 0.8527 acc_val: 0.8351\n",
      "Epoch: 0049 loss_train: 0.3479 acc_train: 0.8517 acc_val: 0.8410\n",
      "Epoch: 0050 loss_train: 0.3510 acc_train: 0.8504 acc_val: 0.8427\n",
      "Epoch: 0051 loss_train: 0.3424 acc_train: 0.8531 acc_val: 0.8448\n",
      "Epoch: 0052 loss_train: 0.3427 acc_train: 0.8536 acc_val: 0.8414\n",
      "Epoch: 0053 loss_train: 0.3398 acc_train: 0.8579 acc_val: 0.8452\n",
      "Epoch: 0054 loss_train: 0.3416 acc_train: 0.8559 acc_val: 0.8436\n",
      "Epoch: 0055 loss_train: 0.3423 acc_train: 0.8543 acc_val: 0.8393\n",
      "Epoch: 0056 loss_train: 0.3315 acc_train: 0.8584 acc_val: 0.8490\n",
      "Epoch: 0057 loss_train: 0.3348 acc_train: 0.8587 acc_val: 0.8406\n",
      "Epoch: 0058 loss_train: 0.3384 acc_train: 0.8593 acc_val: 0.8452\n",
      "Epoch: 0059 loss_train: 0.3248 acc_train: 0.8618 acc_val: 0.8507\n",
      "Epoch: 0060 loss_train: 0.3184 acc_train: 0.8629 acc_val: 0.8495\n",
      "Epoch: 0061 loss_train: 0.3248 acc_train: 0.8611 acc_val: 0.8503\n",
      "Epoch: 0062 loss_train: 0.3205 acc_train: 0.8618 acc_val: 0.8469\n",
      "Epoch: 0063 loss_train: 0.3187 acc_train: 0.8613 acc_val: 0.8537\n",
      "Epoch: 0064 loss_train: 0.3153 acc_train: 0.8626 acc_val: 0.8537\n",
      "Epoch: 0065 loss_train: 0.3147 acc_train: 0.8664 acc_val: 0.8482\n",
      "Epoch: 0066 loss_train: 0.3106 acc_train: 0.8653 acc_val: 0.8482\n",
      "Epoch: 0067 loss_train: 0.3086 acc_train: 0.8660 acc_val: 0.8482\n",
      "Epoch: 0068 loss_train: 0.3110 acc_train: 0.8642 acc_val: 0.8507\n",
      "Epoch: 0069 loss_train: 0.3064 acc_train: 0.8675 acc_val: 0.8478\n",
      "Epoch: 0070 loss_train: 0.3031 acc_train: 0.8675 acc_val: 0.8541\n",
      "Epoch: 0071 loss_train: 0.3045 acc_train: 0.8693 acc_val: 0.8474\n",
      "Epoch: 0072 loss_train: 0.2960 acc_train: 0.8723 acc_val: 0.8575\n",
      "Epoch: 0073 loss_train: 0.3065 acc_train: 0.8709 acc_val: 0.8520\n",
      "Epoch: 0074 loss_train: 0.3010 acc_train: 0.8669 acc_val: 0.8592\n",
      "Epoch: 0075 loss_train: 0.2937 acc_train: 0.8759 acc_val: 0.8609\n",
      "Epoch: 0076 loss_train: 0.2903 acc_train: 0.8727 acc_val: 0.8567\n",
      "Epoch: 0077 loss_train: 0.2923 acc_train: 0.8728 acc_val: 0.8592\n",
      "Epoch: 0078 loss_train: 0.2900 acc_train: 0.8741 acc_val: 0.8567\n",
      "Epoch: 0079 loss_train: 0.2856 acc_train: 0.8768 acc_val: 0.8558\n",
      "Epoch: 0080 loss_train: 0.2856 acc_train: 0.8750 acc_val: 0.8638\n",
      "Epoch: 0081 loss_train: 0.2879 acc_train: 0.8735 acc_val: 0.8567\n",
      "Epoch: 0082 loss_train: 0.2823 acc_train: 0.8787 acc_val: 0.8630\n",
      "Epoch: 0083 loss_train: 0.2843 acc_train: 0.8726 acc_val: 0.8630\n",
      "Epoch: 0084 loss_train: 0.2788 acc_train: 0.8792 acc_val: 0.8626\n",
      "Epoch: 0085 loss_train: 0.2782 acc_train: 0.8782 acc_val: 0.8613\n",
      "Epoch: 0086 loss_train: 0.2815 acc_train: 0.8761 acc_val: 0.8558\n",
      "Epoch: 0087 loss_train: 0.2760 acc_train: 0.8800 acc_val: 0.8533\n",
      "Epoch: 0088 loss_train: 0.2770 acc_train: 0.8799 acc_val: 0.8647\n",
      "Epoch: 0089 loss_train: 0.2708 acc_train: 0.8822 acc_val: 0.8613\n",
      "Epoch: 0090 loss_train: 0.2710 acc_train: 0.8827 acc_val: 0.8634\n",
      "Epoch: 0091 loss_train: 0.2714 acc_train: 0.8821 acc_val: 0.8575\n",
      "Epoch: 0092 loss_train: 0.2690 acc_train: 0.8822 acc_val: 0.8550\n",
      "Epoch: 0093 loss_train: 0.2726 acc_train: 0.8822 acc_val: 0.8609\n",
      "Epoch: 0094 loss_train: 0.2664 acc_train: 0.8863 acc_val: 0.8533\n",
      "Epoch: 0095 loss_train: 0.2627 acc_train: 0.8844 acc_val: 0.8567\n",
      "Epoch: 0096 loss_train: 0.2606 acc_train: 0.8879 acc_val: 0.8651\n",
      "Epoch: 0097 loss_train: 0.2635 acc_train: 0.8860 acc_val: 0.8605\n",
      "Epoch: 0098 loss_train: 0.2637 acc_train: 0.8844 acc_val: 0.8529\n",
      "Epoch: 0099 loss_train: 0.2616 acc_train: 0.8872 acc_val: 0.8571\n",
      "Epoch: 0100 loss_train: 0.2600 acc_train: 0.8860 acc_val: 0.8545\n",
      "Test set results: test_loss= 0.3380 test_accuracy= 0.8495 f1_score= 0.8647 mcc= 0.6968\n"
     ]
    }
   ],
   "source": [
    "from Dataset.Dataset import Twibot20\n",
    "from model import BotRGCN\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import accuracy, init_weights\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "dataset= Twibot20(device=device ,process=False)\n",
    "des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx=dataset.dataloader()\n",
    "\n",
    "botRGCN=BotRGCN(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botRGCN.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botRGCN.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botRGCN)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botRGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7161437-8f38-4c8a-a153-b806b77662d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:37:24.685707Z",
     "iopub.status.busy": "2025-05-22T03:37:24.685263Z",
     "iopub.status.idle": "2025-05-22T03:37:26.639703Z",
     "shell.execute_reply": "2025-05-22T03:37:26.639184Z",
     "shell.execute_reply.started": "2025-05-22T03:37:24.685695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 10:37:26 INFO mlflow.tracking.fluent: Experiment with name 'Dang_TwiBot20_6fd58f' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/b365244b730e4023ae6d4ac7cfaba73a', creation_time=1747885046809, experiment_id='6', last_update_time=1747885046809, lifecycle_stage='active', name='Dang_TwiBot20_6fd58f', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import uuid\n",
    "\n",
    "# Optional: set a custom or unique experiment name\n",
    "experiment_name = f\"Dang_TwiBot20_{uuid.uuid4().hex[:6]}\"\n",
    "mlflow.set_experiment(experiment_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9198336b-fb0d-484f-9d9e-e089fe99e829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:37:45.429153Z",
     "iopub.status.busy": "2025-05-22T03:37:45.428508Z",
     "iopub.status.idle": "2025-05-22T03:37:57.838644Z",
     "shell.execute_reply": "2025-05-22T03:37:57.838146Z",
     "shell.execute_reply.started": "2025-05-22T03:37:45.429136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 10:37:47 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 10:37:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 10:37:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run gaudy-hound-61 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6/runs/527242af7ed34ca381e6cbb5bdfb1777\n",
      "üß™ View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botRGCN)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botRGCN, \"BotRGCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3ee693-01ea-4399-b07b-a026f97f8a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:38:12.971592Z",
     "iopub.status.busy": "2025-05-22T03:38:12.971263Z",
     "iopub.status.idle": "2025-05-22T03:38:16.419880Z",
     "shell.execute_reply": "2025-05-22T03:38:16.419280Z",
     "shell.execute_reply.started": "2025-05-22T03:38:12.971579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.6961 acc_train: 0.4395 acc_val: 0.4402\n",
      "Epoch: 0002 loss_train: 0.6890 acc_train: 0.5645 acc_val: 0.5518\n",
      "Epoch: 0003 loss_train: 0.6845 acc_train: 0.5619 acc_val: 0.5522\n",
      "Epoch: 0004 loss_train: 0.6797 acc_train: 0.5774 acc_val: 0.5611\n",
      "Epoch: 0005 loss_train: 0.6739 acc_train: 0.6403 acc_val: 0.6199\n",
      "Epoch: 0006 loss_train: 0.6674 acc_train: 0.6508 acc_val: 0.6520\n",
      "Epoch: 0007 loss_train: 0.6587 acc_train: 0.6604 acc_val: 0.6554\n",
      "Epoch: 0008 loss_train: 0.6508 acc_train: 0.6570 acc_val: 0.6495\n",
      "Epoch: 0009 loss_train: 0.6412 acc_train: 0.6614 acc_val: 0.6579\n",
      "Epoch: 0010 loss_train: 0.6307 acc_train: 0.6591 acc_val: 0.6677\n",
      "Epoch: 0011 loss_train: 0.6199 acc_train: 0.6654 acc_val: 0.6655\n",
      "Epoch: 0012 loss_train: 0.6072 acc_train: 0.6784 acc_val: 0.6702\n",
      "Epoch: 0013 loss_train: 0.5965 acc_train: 0.6775 acc_val: 0.6655\n",
      "Epoch: 0014 loss_train: 0.5835 acc_train: 0.6953 acc_val: 0.6841\n",
      "Epoch: 0015 loss_train: 0.5808 acc_train: 0.6889 acc_val: 0.6782\n",
      "Epoch: 0016 loss_train: 0.5726 acc_train: 0.7068 acc_val: 0.6905\n",
      "Epoch: 0017 loss_train: 0.5654 acc_train: 0.7121 acc_val: 0.6977\n",
      "Epoch: 0018 loss_train: 0.5712 acc_train: 0.7051 acc_val: 0.7011\n",
      "Epoch: 0019 loss_train: 0.5638 acc_train: 0.7098 acc_val: 0.7015\n",
      "Epoch: 0020 loss_train: 0.5605 acc_train: 0.7138 acc_val: 0.7019\n",
      "Epoch: 0021 loss_train: 0.5610 acc_train: 0.7130 acc_val: 0.7036\n",
      "Epoch: 0022 loss_train: 0.5547 acc_train: 0.7164 acc_val: 0.7027\n",
      "Epoch: 0023 loss_train: 0.5522 acc_train: 0.7133 acc_val: 0.7040\n",
      "Epoch: 0024 loss_train: 0.5476 acc_train: 0.7213 acc_val: 0.7040\n",
      "Epoch: 0025 loss_train: 0.5501 acc_train: 0.7172 acc_val: 0.7070\n",
      "Epoch: 0026 loss_train: 0.5447 acc_train: 0.7238 acc_val: 0.7104\n",
      "Epoch: 0027 loss_train: 0.5420 acc_train: 0.7277 acc_val: 0.7209\n",
      "Epoch: 0028 loss_train: 0.5424 acc_train: 0.7283 acc_val: 0.7116\n",
      "Epoch: 0029 loss_train: 0.5380 acc_train: 0.7292 acc_val: 0.7184\n",
      "Epoch: 0030 loss_train: 0.5378 acc_train: 0.7294 acc_val: 0.7184\n",
      "Epoch: 0031 loss_train: 0.5335 acc_train: 0.7350 acc_val: 0.7163\n",
      "Epoch: 0032 loss_train: 0.5341 acc_train: 0.7281 acc_val: 0.7222\n",
      "Epoch: 0033 loss_train: 0.5301 acc_train: 0.7338 acc_val: 0.7239\n",
      "Epoch: 0034 loss_train: 0.5299 acc_train: 0.7296 acc_val: 0.7163\n",
      "Epoch: 0035 loss_train: 0.5276 acc_train: 0.7315 acc_val: 0.7188\n",
      "Epoch: 0036 loss_train: 0.5247 acc_train: 0.7367 acc_val: 0.7230\n",
      "Epoch: 0037 loss_train: 0.5232 acc_train: 0.7357 acc_val: 0.7180\n",
      "Epoch: 0038 loss_train: 0.5220 acc_train: 0.7359 acc_val: 0.7214\n",
      "Epoch: 0039 loss_train: 0.5221 acc_train: 0.7365 acc_val: 0.7285\n",
      "Epoch: 0040 loss_train: 0.5200 acc_train: 0.7399 acc_val: 0.7230\n",
      "Epoch: 0041 loss_train: 0.5163 acc_train: 0.7418 acc_val: 0.7268\n",
      "Epoch: 0042 loss_train: 0.5140 acc_train: 0.7434 acc_val: 0.7311\n",
      "Epoch: 0043 loss_train: 0.5140 acc_train: 0.7450 acc_val: 0.7302\n",
      "Epoch: 0044 loss_train: 0.5108 acc_train: 0.7485 acc_val: 0.7340\n",
      "Epoch: 0045 loss_train: 0.5102 acc_train: 0.7455 acc_val: 0.7302\n",
      "Epoch: 0046 loss_train: 0.5104 acc_train: 0.7469 acc_val: 0.7336\n",
      "Epoch: 0047 loss_train: 0.5066 acc_train: 0.7478 acc_val: 0.7328\n",
      "Epoch: 0048 loss_train: 0.5044 acc_train: 0.7478 acc_val: 0.7315\n",
      "Epoch: 0049 loss_train: 0.5018 acc_train: 0.7519 acc_val: 0.7362\n",
      "Epoch: 0050 loss_train: 0.5017 acc_train: 0.7491 acc_val: 0.7285\n",
      "Epoch: 0051 loss_train: 0.5014 acc_train: 0.7521 acc_val: 0.7328\n",
      "Epoch: 0052 loss_train: 0.5092 acc_train: 0.7433 acc_val: 0.7239\n",
      "Epoch: 0053 loss_train: 0.5148 acc_train: 0.7432 acc_val: 0.7294\n",
      "Epoch: 0054 loss_train: 0.4963 acc_train: 0.7514 acc_val: 0.7328\n",
      "Epoch: 0055 loss_train: 0.4988 acc_train: 0.7515 acc_val: 0.7340\n",
      "Epoch: 0056 loss_train: 0.5031 acc_train: 0.7539 acc_val: 0.7319\n",
      "Epoch: 0057 loss_train: 0.4906 acc_train: 0.7592 acc_val: 0.7374\n",
      "Epoch: 0058 loss_train: 0.5006 acc_train: 0.7474 acc_val: 0.7294\n",
      "Epoch: 0059 loss_train: 0.4963 acc_train: 0.7590 acc_val: 0.7408\n",
      "Epoch: 0060 loss_train: 0.4890 acc_train: 0.7589 acc_val: 0.7438\n",
      "Epoch: 0061 loss_train: 0.4940 acc_train: 0.7543 acc_val: 0.7353\n",
      "Epoch: 0062 loss_train: 0.4868 acc_train: 0.7612 acc_val: 0.7412\n",
      "Epoch: 0063 loss_train: 0.4896 acc_train: 0.7584 acc_val: 0.7412\n",
      "Epoch: 0064 loss_train: 0.4881 acc_train: 0.7574 acc_val: 0.7345\n",
      "Epoch: 0065 loss_train: 0.4811 acc_train: 0.7612 acc_val: 0.7408\n",
      "Epoch: 0066 loss_train: 0.4870 acc_train: 0.7664 acc_val: 0.7463\n",
      "Epoch: 0067 loss_train: 0.4810 acc_train: 0.7624 acc_val: 0.7378\n",
      "Epoch: 0068 loss_train: 0.4796 acc_train: 0.7650 acc_val: 0.7455\n",
      "Epoch: 0069 loss_train: 0.4839 acc_train: 0.7661 acc_val: 0.7510\n",
      "Epoch: 0070 loss_train: 0.4752 acc_train: 0.7666 acc_val: 0.7450\n",
      "Epoch: 0071 loss_train: 0.4747 acc_train: 0.7690 acc_val: 0.7421\n",
      "Epoch: 0072 loss_train: 0.4763 acc_train: 0.7667 acc_val: 0.7433\n",
      "Epoch: 0073 loss_train: 0.4721 acc_train: 0.7698 acc_val: 0.7446\n",
      "Epoch: 0074 loss_train: 0.4708 acc_train: 0.7739 acc_val: 0.7421\n",
      "Epoch: 0075 loss_train: 0.4689 acc_train: 0.7733 acc_val: 0.7459\n",
      "Epoch: 0076 loss_train: 0.4680 acc_train: 0.7712 acc_val: 0.7455\n",
      "Epoch: 0077 loss_train: 0.4667 acc_train: 0.7772 acc_val: 0.7497\n",
      "Epoch: 0078 loss_train: 0.4638 acc_train: 0.7787 acc_val: 0.7497\n",
      "Epoch: 0079 loss_train: 0.4629 acc_train: 0.7781 acc_val: 0.7493\n",
      "Epoch: 0080 loss_train: 0.4621 acc_train: 0.7807 acc_val: 0.7510\n",
      "Epoch: 0081 loss_train: 0.4664 acc_train: 0.7701 acc_val: 0.7463\n",
      "Epoch: 0082 loss_train: 0.4801 acc_train: 0.7670 acc_val: 0.7383\n",
      "Epoch: 0083 loss_train: 0.4889 acc_train: 0.7577 acc_val: 0.7323\n",
      "Epoch: 0084 loss_train: 0.4792 acc_train: 0.7660 acc_val: 0.7404\n",
      "Epoch: 0085 loss_train: 0.4532 acc_train: 0.7841 acc_val: 0.7510\n",
      "Epoch: 0086 loss_train: 0.4704 acc_train: 0.7669 acc_val: 0.7383\n",
      "Epoch: 0087 loss_train: 0.4659 acc_train: 0.7791 acc_val: 0.7404\n",
      "Epoch: 0088 loss_train: 0.4531 acc_train: 0.7842 acc_val: 0.7543\n",
      "Epoch: 0089 loss_train: 0.4673 acc_train: 0.7702 acc_val: 0.7404\n",
      "Epoch: 0090 loss_train: 0.4540 acc_train: 0.7850 acc_val: 0.7488\n",
      "Epoch: 0091 loss_train: 0.4517 acc_train: 0.7876 acc_val: 0.7535\n",
      "Epoch: 0092 loss_train: 0.4590 acc_train: 0.7747 acc_val: 0.7429\n",
      "Epoch: 0093 loss_train: 0.4461 acc_train: 0.7893 acc_val: 0.7564\n",
      "Epoch: 0094 loss_train: 0.4519 acc_train: 0.7850 acc_val: 0.7514\n",
      "Epoch: 0095 loss_train: 0.4539 acc_train: 0.7757 acc_val: 0.7412\n",
      "Epoch: 0096 loss_train: 0.4405 acc_train: 0.7920 acc_val: 0.7539\n",
      "Epoch: 0097 loss_train: 0.4473 acc_train: 0.7885 acc_val: 0.7526\n",
      "Epoch: 0098 loss_train: 0.4487 acc_train: 0.7817 acc_val: 0.7501\n",
      "Epoch: 0099 loss_train: 0.4373 acc_train: 0.7940 acc_val: 0.7535\n",
      "Epoch: 0100 loss_train: 0.4404 acc_train: 0.7946 acc_val: 0.7526\n",
      "Test set results: test_loss= 0.5426 test_accuracy= 0.7371 f1_score= 0.7718 mcc= 0.4693\n"
     ]
    }
   ],
   "source": [
    "from model import BotGCN\n",
    "\n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "botGCN=BotGCN(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botGCN.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botRGCN.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botGCN)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b12be0-ae4b-4211-b618-8b8772ea59e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:38:22.654655Z",
     "iopub.status.busy": "2025-05-22T03:38:22.654342Z",
     "iopub.status.idle": "2025-05-22T03:38:32.133054Z",
     "shell.execute_reply": "2025-05-22T03:38:32.132524Z",
     "shell.execute_reply.started": "2025-05-22T03:38:22.654642Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 10:38:24 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 10:38:27 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 10:38:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bald-zebra-608 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6/runs/bc8296122caa446da63459c981b99bb2\n",
      "üß™ View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimiser\": \"AdamW\"\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botGCN)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botGCN, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e385260-f873-4a80-8af1-b62e21a70893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:38:32.133988Z",
     "iopub.status.busy": "2025-05-22T03:38:32.133686Z",
     "iopub.status.idle": "2025-05-22T03:38:36.466204Z",
     "shell.execute_reply": "2025-05-22T03:38:36.465575Z",
     "shell.execute_reply.started": "2025-05-22T03:38:32.133976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.8152 acc_train: 0.5291 acc_val: 0.5188\n",
      "Epoch: 0002 loss_train: 0.6962 acc_train: 0.5927 acc_val: 0.5725\n",
      "Epoch: 0003 loss_train: 0.6722 acc_train: 0.6065 acc_val: 0.5877\n",
      "Epoch: 0004 loss_train: 0.6409 acc_train: 0.6274 acc_val: 0.6144\n",
      "Epoch: 0005 loss_train: 0.6366 acc_train: 0.6593 acc_val: 0.6541\n",
      "Epoch: 0006 loss_train: 0.6329 acc_train: 0.6651 acc_val: 0.6638\n",
      "Epoch: 0007 loss_train: 0.6193 acc_train: 0.6667 acc_val: 0.6664\n",
      "Epoch: 0008 loss_train: 0.6146 acc_train: 0.6552 acc_val: 0.6562\n",
      "Epoch: 0009 loss_train: 0.6224 acc_train: 0.6468 acc_val: 0.6368\n",
      "Epoch: 0010 loss_train: 0.6104 acc_train: 0.6608 acc_val: 0.6537\n",
      "Epoch: 0011 loss_train: 0.6011 acc_train: 0.6755 acc_val: 0.6630\n",
      "Epoch: 0012 loss_train: 0.6087 acc_train: 0.6767 acc_val: 0.6774\n",
      "Epoch: 0013 loss_train: 0.5985 acc_train: 0.6851 acc_val: 0.6863\n",
      "Epoch: 0014 loss_train: 0.5936 acc_train: 0.6818 acc_val: 0.6846\n",
      "Epoch: 0015 loss_train: 0.5862 acc_train: 0.6816 acc_val: 0.6778\n",
      "Epoch: 0016 loss_train: 0.5891 acc_train: 0.6772 acc_val: 0.6710\n",
      "Epoch: 0017 loss_train: 0.5810 acc_train: 0.6840 acc_val: 0.6808\n",
      "Epoch: 0018 loss_train: 0.5750 acc_train: 0.6959 acc_val: 0.6795\n",
      "Epoch: 0019 loss_train: 0.5757 acc_train: 0.6987 acc_val: 0.6989\n",
      "Epoch: 0020 loss_train: 0.5716 acc_train: 0.7103 acc_val: 0.6934\n",
      "Epoch: 0021 loss_train: 0.5616 acc_train: 0.7113 acc_val: 0.6888\n",
      "Epoch: 0022 loss_train: 0.5601 acc_train: 0.7042 acc_val: 0.6875\n",
      "Epoch: 0023 loss_train: 0.5607 acc_train: 0.7031 acc_val: 0.6905\n",
      "Epoch: 0024 loss_train: 0.5521 acc_train: 0.7148 acc_val: 0.7061\n",
      "Epoch: 0025 loss_train: 0.5519 acc_train: 0.7144 acc_val: 0.7057\n",
      "Epoch: 0026 loss_train: 0.5498 acc_train: 0.7174 acc_val: 0.7023\n",
      "Epoch: 0027 loss_train: 0.5460 acc_train: 0.7176 acc_val: 0.6960\n",
      "Epoch: 0028 loss_train: 0.5455 acc_train: 0.7171 acc_val: 0.7049\n",
      "Epoch: 0029 loss_train: 0.5391 acc_train: 0.7216 acc_val: 0.7082\n",
      "Epoch: 0030 loss_train: 0.5383 acc_train: 0.7247 acc_val: 0.7175\n",
      "Epoch: 0031 loss_train: 0.5344 acc_train: 0.7316 acc_val: 0.7146\n",
      "Epoch: 0032 loss_train: 0.5339 acc_train: 0.7258 acc_val: 0.7053\n",
      "Epoch: 0033 loss_train: 0.5327 acc_train: 0.7280 acc_val: 0.7121\n",
      "Epoch: 0034 loss_train: 0.5274 acc_train: 0.7295 acc_val: 0.7167\n",
      "Epoch: 0035 loss_train: 0.5252 acc_train: 0.7352 acc_val: 0.7230\n",
      "Epoch: 0036 loss_train: 0.5230 acc_train: 0.7371 acc_val: 0.7133\n",
      "Epoch: 0037 loss_train: 0.5213 acc_train: 0.7381 acc_val: 0.7256\n",
      "Epoch: 0038 loss_train: 0.5188 acc_train: 0.7364 acc_val: 0.7150\n",
      "Epoch: 0039 loss_train: 0.5162 acc_train: 0.7445 acc_val: 0.7294\n",
      "Epoch: 0040 loss_train: 0.5146 acc_train: 0.7428 acc_val: 0.7214\n",
      "Epoch: 0041 loss_train: 0.5096 acc_train: 0.7473 acc_val: 0.7311\n",
      "Epoch: 0042 loss_train: 0.5095 acc_train: 0.7466 acc_val: 0.7345\n",
      "Epoch: 0043 loss_train: 0.5059 acc_train: 0.7482 acc_val: 0.7328\n",
      "Epoch: 0044 loss_train: 0.5057 acc_train: 0.7516 acc_val: 0.7340\n",
      "Epoch: 0045 loss_train: 0.4996 acc_train: 0.7574 acc_val: 0.7455\n",
      "Epoch: 0046 loss_train: 0.4981 acc_train: 0.7563 acc_val: 0.7366\n",
      "Epoch: 0047 loss_train: 0.4925 acc_train: 0.7613 acc_val: 0.7442\n",
      "Epoch: 0048 loss_train: 0.4900 acc_train: 0.7613 acc_val: 0.7408\n",
      "Epoch: 0049 loss_train: 0.4867 acc_train: 0.7632 acc_val: 0.7484\n",
      "Epoch: 0050 loss_train: 0.4823 acc_train: 0.7642 acc_val: 0.7471\n",
      "Epoch: 0051 loss_train: 0.4856 acc_train: 0.7615 acc_val: 0.7476\n",
      "Epoch: 0052 loss_train: 0.4801 acc_train: 0.7676 acc_val: 0.7488\n",
      "Epoch: 0053 loss_train: 0.4787 acc_train: 0.7711 acc_val: 0.7497\n",
      "Epoch: 0054 loss_train: 0.4737 acc_train: 0.7748 acc_val: 0.7522\n",
      "Epoch: 0055 loss_train: 0.4706 acc_train: 0.7764 acc_val: 0.7658\n",
      "Epoch: 0056 loss_train: 0.4680 acc_train: 0.7751 acc_val: 0.7535\n",
      "Epoch: 0057 loss_train: 0.4627 acc_train: 0.7828 acc_val: 0.7700\n",
      "Epoch: 0058 loss_train: 0.4572 acc_train: 0.7849 acc_val: 0.7594\n",
      "Epoch: 0059 loss_train: 0.4577 acc_train: 0.7871 acc_val: 0.7691\n",
      "Epoch: 0060 loss_train: 0.4586 acc_train: 0.7847 acc_val: 0.7662\n",
      "Epoch: 0061 loss_train: 0.4536 acc_train: 0.7926 acc_val: 0.7704\n",
      "Epoch: 0062 loss_train: 0.4508 acc_train: 0.7905 acc_val: 0.7649\n",
      "Epoch: 0063 loss_train: 0.4465 acc_train: 0.7916 acc_val: 0.7734\n",
      "Epoch: 0064 loss_train: 0.4413 acc_train: 0.7950 acc_val: 0.7712\n",
      "Epoch: 0065 loss_train: 0.4445 acc_train: 0.7975 acc_val: 0.7729\n",
      "Epoch: 0066 loss_train: 0.4378 acc_train: 0.7944 acc_val: 0.7751\n",
      "Epoch: 0067 loss_train: 0.4367 acc_train: 0.7998 acc_val: 0.7734\n",
      "Epoch: 0068 loss_train: 0.4327 acc_train: 0.8007 acc_val: 0.7784\n",
      "Epoch: 0069 loss_train: 0.4329 acc_train: 0.7984 acc_val: 0.7801\n",
      "Epoch: 0070 loss_train: 0.4281 acc_train: 0.8053 acc_val: 0.7742\n",
      "Epoch: 0071 loss_train: 0.4291 acc_train: 0.8029 acc_val: 0.7839\n",
      "Epoch: 0072 loss_train: 0.4291 acc_train: 0.8044 acc_val: 0.7780\n",
      "Epoch: 0073 loss_train: 0.4217 acc_train: 0.8084 acc_val: 0.7827\n",
      "Epoch: 0074 loss_train: 0.4180 acc_train: 0.8143 acc_val: 0.7877\n",
      "Epoch: 0075 loss_train: 0.4149 acc_train: 0.8122 acc_val: 0.7886\n",
      "Epoch: 0076 loss_train: 0.4180 acc_train: 0.8085 acc_val: 0.7814\n",
      "Epoch: 0077 loss_train: 0.4118 acc_train: 0.8129 acc_val: 0.7860\n",
      "Epoch: 0078 loss_train: 0.4073 acc_train: 0.8142 acc_val: 0.7860\n",
      "Epoch: 0079 loss_train: 0.4059 acc_train: 0.8166 acc_val: 0.7915\n",
      "Epoch: 0080 loss_train: 0.4099 acc_train: 0.8129 acc_val: 0.7877\n",
      "Epoch: 0081 loss_train: 0.4035 acc_train: 0.8171 acc_val: 0.7932\n",
      "Epoch: 0082 loss_train: 0.3988 acc_train: 0.8210 acc_val: 0.7899\n",
      "Epoch: 0083 loss_train: 0.3995 acc_train: 0.8170 acc_val: 0.7877\n",
      "Epoch: 0084 loss_train: 0.3976 acc_train: 0.8206 acc_val: 0.7928\n",
      "Epoch: 0085 loss_train: 0.3924 acc_train: 0.8256 acc_val: 0.7945\n",
      "Epoch: 0086 loss_train: 0.3875 acc_train: 0.8276 acc_val: 0.7920\n",
      "Epoch: 0087 loss_train: 0.3868 acc_train: 0.8286 acc_val: 0.8034\n",
      "Epoch: 0088 loss_train: 0.3843 acc_train: 0.8263 acc_val: 0.7911\n",
      "Epoch: 0089 loss_train: 0.3825 acc_train: 0.8291 acc_val: 0.8000\n",
      "Epoch: 0090 loss_train: 0.3841 acc_train: 0.8276 acc_val: 0.7975\n",
      "Epoch: 0091 loss_train: 0.3806 acc_train: 0.8302 acc_val: 0.7983\n",
      "Epoch: 0092 loss_train: 0.3829 acc_train: 0.8250 acc_val: 0.7975\n",
      "Epoch: 0093 loss_train: 0.3887 acc_train: 0.8275 acc_val: 0.7865\n",
      "Epoch: 0094 loss_train: 0.3796 acc_train: 0.8309 acc_val: 0.8008\n",
      "Epoch: 0095 loss_train: 0.3710 acc_train: 0.8381 acc_val: 0.7983\n",
      "Epoch: 0096 loss_train: 0.3712 acc_train: 0.8346 acc_val: 0.8034\n",
      "Epoch: 0097 loss_train: 0.3756 acc_train: 0.8318 acc_val: 0.7860\n",
      "Epoch: 0098 loss_train: 0.3741 acc_train: 0.8311 acc_val: 0.8055\n",
      "Epoch: 0099 loss_train: 0.3642 acc_train: 0.8413 acc_val: 0.7987\n",
      "Epoch: 0100 loss_train: 0.3624 acc_train: 0.8401 acc_val: 0.8004\n",
      "Test set results: test_loss= 0.4461 test_accuracy= 0.8174 f1_score= 0.8444 mcc= 0.6379\n"
     ]
    }
   ],
   "source": [
    "from model import BotGAT\n",
    "\n",
    "embedding_size,dropout,lr,weight_decay=128,0.3,1e-3,5e-3\n",
    "\n",
    "botGAT=BotGAT(num_prop_size=5,cat_prop_size=3,embedding_dimension=embedding_size).to(device)\n",
    "\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(botGAT.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "botGAT.apply(init_weights)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    acc_train, loss_train = train(epoch,botGAT)\n",
    "    \n",
    "acc_test, loss_test, f1, mcc = test(botGAT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f55860-a443-40f9-afcd-6048e8ee31fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:38:36.467171Z",
     "iopub.status.busy": "2025-05-22T03:38:36.466874Z",
     "iopub.status.idle": "2025-05-22T03:38:46.801226Z",
     "shell.execute_reply": "2025-05-22T03:38:46.800752Z",
     "shell.execute_reply.started": "2025-05-22T03:38:36.467161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/22 10:38:38 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/22 10:38:42 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/05/22 10:38:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run melodic-fox-832 at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6/runs/d11213f31c0749249e28a50f24e2f81c\n",
      "üß™ View experiment at: https://dagshub.com/quangbhdang/COSC2984-SMNA-Assignment.mlflow/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "# Logging experiment results\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": embedding_size,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimiser\": \"AdamW\"\n",
    "    })\n",
    "\n",
    "    # Log final test metrics (replace with your actual variable values)\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\":acc_train.item() if isinstance(acc_train, torch.Tensor) else acc_train,\n",
    "        \"train_loss\": loss_train.item() if isinstance(acc_train, torch.Tensor) else loss_train,\n",
    "        \"test_accuracy\": acc_test.item() if isinstance(acc_test, torch.Tensor) else acc_test,\n",
    "        \"test_loss\": loss_test.item() if isinstance(loss_test, torch.Tensor) else loss_test,\n",
    "        \"f1_score\": f1,\n",
    "        \"matthew_coeff\": mcc\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(botGAT)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    # Optionally log model\n",
    "    mlflow.pytorch.log_model(botGAT, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a5d04-c87f-4411-890d-24f9526af2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
